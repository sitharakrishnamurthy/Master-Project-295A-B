<!DOCTYPE html>
<meta charset="utf-8">
<title>Graph Runner</title>
<link rel="stylesheet" href="../stylesheet/try_on.css">
<script>
  // Quick workaround for Safari 13 bug: see b/143301307 for more details.
  const tempUnused = WebAssembly.Module;
</script>
<script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script src="../javascript/mediapipe/hair_segmentation_bin.js"></script>

<script>
  window.Module = ModuleFactory({
    locateFile: function(f, g) {
      return f; },
    postRun: [],
  });
</script>
<script src="../javascript/mediapipe/hair_segmentation_loader.js"></script>


<script>
  function fix(old_graph) {
    // Replace references to mediapipe with the old drishti references.
    let new_graph = old_graph.replace(/\[type\.googleapis\.com\/mediapipe\.(.*)\]/g,
      '[drishti.$1.ext]')
    new_graph = new_graph.replace(/\bnode_options:/g, 'options:');
    return new_graph;
  }

  function setGraph(main_graph, subgraphs) {
    // Full-size GPU input, front-facing, and our processor will render output
    // using OpenGL directly to canvas, unless GPU input has been disabled.
    const videoProcessor = new VideoProcessor(1, true, true, true);
    videoProcessor.initialize();

    const cpuXenoEffects = new CpuXenoEffects();
    cpuXenoEffects.setGlMirrorMode(true);
    videoProcessor.setFrameProcessor(cpuXenoEffects);
    videoProcessor.setOutputProcessor({
      process: (detections) => {
        let detectionString = 'No Detections.';
        if (detections && detections.current_mspf > 0.0) {
          detectionString = (1000.0 / detections.current_mspf).toFixed(2) + ' fps';
        }
        document.getElementById('message').textContent = detectionString;
      }
    });
    cpuXenoEffects.setSubgraphs(subgraphs.map(d => new TextEncoder("utf-8").encode(fix(d))));
    cpuXenoEffects.setGraph(new TextEncoder("utf-8").encode(fix(main_graph)), false);  // false, since text
  }

  window.Module['postRun'].push(() => {
    setTimeout(() => {
      let subgraphs = [];
      let main_graph;
      $.getJSON("/javascript/mediapipe/mediapipe_graph.json", function(json)  {
        var mediagraph = json;
        let temp = mediagraph.slice(0,-63)
        let colors = "color { r: " + window.parent.red +" g: "+ window.parent.green +" b: "+ window.parent.blue +" }\n      mask_channel: RED\n    }\n  }\n}\n"
        main_graph = temp.concat(colors)
        setGraph(main_graph, subgraphs);
      });
    }, 1000);
  });
</script>

<html>
<head>
</head>
<body>
    <video id="video" playsinline loop style="display: none;" >
        <!-- Uncomment below line to use canned video instead of camera. -->
        <!-- <source src="people.mp4"  type="video/mp4"> -->
        Loading embedded camera/video failed.
    </video>
    <canvas id="output"></canvas>
    <div style="display: none;">
      <svg id="notch" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  xml:space="preserve">
          <style type="text/css">
          .st0{fill:#FFFFFF;stroke:#000000;stroke-miterlimit:10;}
          </style> 
          <path d="M170.91,96"/>
          <path d="M422.64,0L422.64,0L219.91,0v0H104.32c11.08,0.09,15.74,3.87,18.32,14.56c1.02,4.21,1.61,8.53,2.72,12.72
          c2.81,10.58,10.56,17.27,21.42,17.3c24.38,0.08,48.75,0.12,73.13,0.12v0c67.57,0,135.15,0,202.72,0v0
          c25.63-0.01,51.26-0.04,76.89-0.12c11.01-0.03,18.44-6.44,21.51-17.14c0.17-0.6,0.32-1.2,0.43-1.81
          C525.11,4.81,528.41,0.69,540.82,0H422.64z"/>
      </svg>
</div>
  <div id="message" class="abs" id="message" style="display: none;">Initializing...</div>
</div>
</div>
</body>

<!-- Load helper scripts -->
<script src="../javascript/mediapipe/wasm_heap_writer.js"></script>
<script src="../javascript/mediapipe/cpu_xeno_effects.js"></script>
<script src="../javascript/mediapipe/video_processor.js"></script>

</html>
